{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97954655-7222-46a5-a4d7-c106352ab610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from merlin import QuantumLayer, ComputationSpace, LexGrouping\n",
    "from merlin.builder import CircuitBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521d6e3f-d7c5-4e3a-ac34-adc4259a1f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822e6d4a-fa33-4ae1-96f9-e789a97e1ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import perceval as pcvl\n",
    "import torch\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from merlin.algorithms.kernels import FeatureMap, FidelityKernel, KernelCircuitBuilder\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48b5bf5-be2c-47d0-a943-5d62c86e2dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import  MinMaxScaler\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "def load_data(file_path: str) -> pd.DataFrame:\n",
    "    print(f\"Loading data from {file_path}\")\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "def preprocess_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    X = df.iloc[:, 1:-1].values\n",
    "    y = df.iloc[:, -1].values\n",
    "    print('X = ', X)\n",
    "\n",
    "    sc_X = MinMaxScaler()\n",
    "    X_train = sc_X.fit_transform(X)\n",
    "    print(\"X train = \", X_train)\n",
    "            \n",
    "    print(\"Preprocessing complete.\")\n",
    "\n",
    "    return X_train,y\n",
    "\n",
    "def save_cleaned_data(df: pd.DataFrame, output_path: str) -> None:\n",
    "    print(f\"\\nSaving cleaned data to {output_path}\")\n",
    "    df= pd.DataFrame(df, columns=['income','credit_utilization','payment_history','num_open_accounts','debt_to_income','loan_amount'])\n",
    "    \n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(\"Done.\")\n",
    "\n",
    "\n",
    "input_path = \"data/credit_train.csv\"\n",
    "output_path = \"data/credit_train_cleaned.csv\"\n",
    "\n",
    "\n",
    "\n",
    "df = load_data(input_path)\n",
    "# inspect_data(df)\n",
    "df_cleaned,y_train = preprocess_data(df)\n",
    "# inspect_data(df_cleaned)\n",
    "save_cleaned_data(df_cleaned, output_path)\n",
    "\n",
    "\n",
    "test_input_path = \"data/credit_test.csv\"\n",
    "test_output_path = \"data/credit_test_cleaned.csv\"\n",
    "\n",
    "df_test = load_data(test_input_path)\n",
    "# inspect_data(df)\n",
    "df_test_cleaned,y_test = preprocess_data(df_test)\n",
    "# inspect_data(df_cleaned)\n",
    "save_cleaned_data(df_test_cleaned, test_output_path)\n",
    "\n",
    "# ============================================================\n",
    "# 1. Tensor conversions & DataLoader\n",
    "# ============================================================\n",
    "def convert_dataset_to_tensor(x_train, x_test, y_train, y_test):\n",
    "    x_train = torch.tensor(x_train, dtype=torch.float32)\n",
    "    x_test = torch.tensor(x_test, dtype=torch.float32)\n",
    "    y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "    y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "\n",
    "def convert_tensor_to_loader(x_train, y_train, batch_size=6):\n",
    "    train_dataset = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "    return train_loader\n",
    "\n",
    "\n",
    "\n",
    "x_train_np=df_cleaned\n",
    "y_train_np=y_train\n",
    "\n",
    "x_test_np=df_test_cleaned\n",
    "y_test_np=y_test\n",
    "# Number of classes inferred from training labels\n",
    "num_classes = int(len(np.unique(y_train_np)))\n",
    "\n",
    "# Convert to tensors\n",
    "x_train, x_test, y_train, y_test = convert_dataset_to_tensor(\n",
    "    x_train_np, x_test_np, y_train_np, y_test_np\n",
    ")\n",
    "\n",
    "\n",
    "# Build DataLoader\n",
    "#train_loader = convert_tensor_to_loader(x_train, y_train, batch_size=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c1996b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(x_test_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc58a39-3ac0-48f8-98e7-e2db69d79c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = FidelityKernel.simple(\n",
    "    input_size=6,\n",
    "    n_modes=6,\n",
    "    shots=0,  # exact probabilities\n",
    "    no_bunching=False,\n",
    "    dtype=torch.float32,\n",
    "    device=torch.device(\"cpu\"),\n",
    ")\n",
    "\n",
    "K_train = kernel(x_train)\n",
    "K_test = kernel(x_test, x_train)\n",
    "\n",
    "print(\"Train Gram shape:\", K_train.shape)\n",
    "print(\"Test Gram shape:\", K_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86daf27-7a57-420d-948c-6da358055502",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(kernel=\"precomputed\")\n",
    "svc.fit(K_train.detach().numpy(), y_train)\n",
    "train_accuracy = svc.score(K_train.detach().numpy(), y_train)\n",
    "print(f\"SVM train accuracy (precomputed kernel): {train_accuracy:.3f}\")\n",
    "test_accuracy = svc.score(K_test.detach().numpy(), y_test)\n",
    "print(f\"SVM accuracy (precomputed kernel): {test_accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691a1d94-0f58-4b59-9292-a42fb956b965",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUC\n",
    "#F1\n",
    "#Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c120bf-94f5-428c-95f3-ca025a4eec01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecfa58d-a43c-470e-bffd-6bc6381bf74c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Big-Quantum-Hackathon-with-Qatar-Islamic-Bank-and-Quandela (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
