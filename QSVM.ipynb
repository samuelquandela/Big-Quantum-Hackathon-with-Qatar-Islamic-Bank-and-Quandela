{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97954655-7222-46a5-a4d7-c106352ab610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from merlin import QuantumLayer, ComputationSpace, LexGrouping\n",
    "from merlin.builder import CircuitBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "521d6e3f-d7c5-4e3a-ac34-adc4259a1f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "822e6d4a-fa33-4ae1-96f9-e789a97e1ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import perceval as pcvl\n",
    "import torch\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from merlin.algorithms.kernels import FeatureMap, FidelityKernel, KernelCircuitBuilder\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a48b5bf5-be2c-47d0-a943-5d62c86e2dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from data/credit_train.csv\n",
      "X =  [[ 0.619  0.529  0.418 14.     0.308  0.516]\n",
      " [ 0.473  0.434  0.829 17.     0.352  0.945]\n",
      " [ 0.389  0.724  0.848  7.     0.604  0.629]\n",
      " ...\n",
      " [ 0.328  0.94   0.693  2.     0.809  0.826]\n",
      " [ 0.452  0.424  0.753 14.     0.383  0.646]\n",
      " [ 0.416  0.526  0.503 15.     0.489  0.606]]\n",
      "X train =  [[0.61158798 0.55075594 0.37852495 0.8125     0.308      0.31054131]\n",
      " [0.45493562 0.44816415 0.82429501 1.         0.352      0.92165242]\n",
      " [0.36480687 0.76133909 0.84490239 0.375      0.604      0.47150997]\n",
      " ...\n",
      " [0.29935622 0.99460043 0.67678959 0.0625     0.809      0.75213675]\n",
      " [0.43240343 0.43736501 0.74186551 0.8125     0.383      0.4957265 ]\n",
      " [0.39377682 0.5475162  0.47071584 0.875      0.489      0.43874644]]\n",
      "Preprocessing complete.\n",
      "\n",
      "Saving cleaned data to data/credit_train_cleaned.csv\n",
      "Done.\n",
      "Loading data from data/credit_test.csv\n",
      "X =  [[ 0.629  0.465  0.489 10.     0.419  0.764]\n",
      " [ 0.676  0.178  0.616  9.     0.181  0.641]\n",
      " [ 0.678  0.466  0.8   13.     0.338  0.569]\n",
      " ...\n",
      " [ 0.37   0.377  0.725  4.     0.397  0.942]\n",
      " [ 0.771  0.4    0.496 10.     0.111  0.497]\n",
      " [ 0.947  0.677  0.905  9.     0.388  0.565]]\n",
      "X train =  [[0.60689655 0.46519337 0.40828402 0.5625     0.49005848 0.68575233]\n",
      " [0.66091954 0.1480663  0.55857988 0.5        0.21169591 0.52197071]\n",
      " [0.66321839 0.46629834 0.77633136 0.75       0.39532164 0.42609854]\n",
      " ...\n",
      " [0.3091954  0.3679558  0.68757396 0.1875     0.46432749 0.92276964]\n",
      " [0.77011494 0.39337017 0.41656805 0.5625     0.12982456 0.33022636]\n",
      " [0.97241379 0.69944751 0.90059172 0.5        0.45380117 0.4207723 ]]\n",
      "Preprocessing complete.\n",
      "\n",
      "Saving cleaned data to data/credit_test_cleaned.csv\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import  MinMaxScaler\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "def load_data(file_path: str) -> pd.DataFrame:\n",
    "    print(f\"Loading data from {file_path}\")\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "def preprocess_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    X = df.iloc[:, 1:-1].values\n",
    "    y = df.iloc[:, -1].values\n",
    "    print('X = ', X)\n",
    "\n",
    "    sc_X = MinMaxScaler()\n",
    "    X_train = sc_X.fit_transform(X)\n",
    "    print(\"X train = \", X_train)\n",
    "            \n",
    "    print(\"Preprocessing complete.\")\n",
    "\n",
    "    return X_train,y\n",
    "\n",
    "def save_cleaned_data(df: pd.DataFrame, output_path: str) -> None:\n",
    "    print(f\"\\nSaving cleaned data to {output_path}\")\n",
    "    df= pd.DataFrame(df, columns=['income','credit_utilization','payment_history','num_open_accounts','debt_to_income','loan_amount'])\n",
    "    \n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(\"Done.\")\n",
    "\n",
    "\n",
    "input_path = \"data/credit_train.csv\"\n",
    "output_path = \"data/credit_train_cleaned.csv\"\n",
    "\n",
    "\n",
    "\n",
    "df = load_data(input_path)\n",
    "# inspect_data(df)\n",
    "df_cleaned,y_train = preprocess_data(df)\n",
    "# inspect_data(df_cleaned)\n",
    "save_cleaned_data(df_cleaned, output_path)\n",
    "\n",
    "\n",
    "test_input_path = \"data/credit_test.csv\"\n",
    "test_output_path = \"data/credit_test_cleaned.csv\"\n",
    "\n",
    "df_test = load_data(test_input_path)\n",
    "# inspect_data(df)\n",
    "df_test_cleaned,y_test = preprocess_data(df_test)\n",
    "# inspect_data(df_cleaned)\n",
    "save_cleaned_data(df_test_cleaned, test_output_path)\n",
    "\n",
    "# ============================================================\n",
    "# 1. Tensor conversions & DataLoader\n",
    "# ============================================================\n",
    "def convert_dataset_to_tensor(x_train, x_test, y_train, y_test):\n",
    "    x_train = torch.tensor(x_train, dtype=torch.float32)\n",
    "    x_test = torch.tensor(x_test, dtype=torch.float32)\n",
    "    y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "    y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "\n",
    "def convert_tensor_to_loader(x_train, y_train, batch_size=6):\n",
    "    train_dataset = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "    return train_loader\n",
    "\n",
    "\n",
    "\n",
    "x_train_np=df_cleaned\n",
    "y_train_np=y_train\n",
    "\n",
    "x_test_np=df_test_cleaned\n",
    "y_test_np=y_test\n",
    "# Number of classes inferred from training labels\n",
    "num_classes = int(len(np.unique(y_train_np)))\n",
    "\n",
    "# Convert to tensors\n",
    "x_train, x_test, y_train, y_test = convert_dataset_to_tensor(\n",
    "    x_train_np, x_test_np, y_train_np, y_test_np\n",
    ")\n",
    "\n",
    "\n",
    "# Build DataLoader\n",
    "#train_loader = convert_tensor_to_loader(x_train, y_train, batch_size=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1c1996b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240\n"
     ]
    }
   ],
   "source": [
    "print(len(x_test_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebc58a39-3ac0-48f8-98e7-e2db69d79c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Gram shape: torch.Size([600, 600])\n",
      "Test Gram shape: torch.Size([240, 600])\n"
     ]
    }
   ],
   "source": [
    "kernel = FidelityKernel.simple(\n",
    "    input_size=6,\n",
    "    n_modes=6,\n",
    "    shots=0,  # exact probabilities\n",
    "    no_bunching=False,\n",
    "    dtype=torch.float32,\n",
    "    device=torch.device(\"cpu\"),\n",
    ")\n",
    "\n",
    "K_train = kernel(x_train)\n",
    "K_test = kernel(x_test, x_train)\n",
    "\n",
    "print(\"Train Gram shape:\", K_train.shape)\n",
    "print(\"Test Gram shape:\", K_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b86daf27-7a57-420d-948c-6da358055502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM train accuracy (precomputed kernel): 0.932\n",
      "SVM accuracy (precomputed kernel): 0.942\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(kernel=\"precomputed\")\n",
    "svc.fit(K_train.detach().numpy(), y_train)\n",
    "train_accuracy = svc.score(K_train.detach().numpy(), y_train)\n",
    "print(f\"SVM train accuracy (precomputed kernel): {train_accuracy:.3f}\")\n",
    "test_accuracy = svc.score(K_test.detach().numpy(), y_test)\n",
    "print(f\"SVM accuracy (precomputed kernel): {test_accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "691a1d94-0f58-4b59-9292-a42fb956b965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Confusion matrix (test) ===\n",
      "[[180   7]\n",
      " [  7  46]]\n",
      "\n",
      "=== Classification report (test) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.963     0.963     0.963       187\n",
      "           1      0.868     0.868     0.868        53\n",
      "\n",
      "    accuracy                          0.942       240\n",
      "   macro avg      0.915     0.915     0.915       240\n",
      "weighted avg      0.942     0.942     0.942       240\n",
      "\n",
      "\n",
      "Balanced accuracy (test): 0.9152456866108365\n",
      "ROC-AUC (test): 0.9704368883059228\n",
      "PR-AUC (test): 0.9239170118418321\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    balanced_accuracy_score\n",
    ")\n",
    "\n",
    "K_train_np = K_train.detach().numpy()\n",
    "K_test_np = K_test.detach().numpy()\n",
    "y_train_np = y_train.numpy()\n",
    "y_test_np = y_test.numpy()\n",
    "\n",
    "# Predictions\n",
    "y_pred_train = svc.predict(K_train_np)\n",
    "y_pred_test = svc.predict(K_test_np)\n",
    "\n",
    "print(\"\\n=== Confusion matrix (test) ===\")\n",
    "print(confusion_matrix(y_test_np, y_pred_test))\n",
    "\n",
    "print(\"\\n=== Classification report (test) ===\")\n",
    "print(classification_report(y_test_np, y_pred_test, digits=3))\n",
    "\n",
    "print(\"\\nBalanced accuracy (test):\",\n",
    "      balanced_accuracy_score(y_test_np, y_pred_test))\n",
    "\n",
    "# Probabilities / scores for AUC\n",
    "scores_test = svc.decision_function(K_test_np)\n",
    "\n",
    "print(\"ROC-AUC (test):\",\n",
    "      roc_auc_score(y_test_np, scores_test))\n",
    "\n",
    "print(\"PR-AUC (test):\",\n",
    "      average_precision_score(y_test_np, scores_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c120bf-94f5-428c-95f3-ca025a4eec01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecfa58d-a43c-470e-bffd-6bc6381bf74c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Big-Quantum-Hackathon-with-Qatar-Islamic-Bank-and-Quandela (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
